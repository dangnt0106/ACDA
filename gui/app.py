import gradio as gr
import asyncio
import sys
import os 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from tts.processor import (
    process_mixed_text_with_edge,
    process_mixed_text_with_google,
    preview_mixed_text_with_edge,
    preview_mixed_text_with_google
)
from config.config import VOICE_JA_TTS, VOICE_VI_TTS,GOOGLE_JA_VOICES, GOOGLE_VI_VOICES


def run_async(text, ja_voice, vi_voice):
    if not isinstance(ja_voice, str) or not isinstance(vi_voice, str):
        return "‚ùå Voice ph·∫£i l√† ki·ªÉu chu·ªói.", None

    result = asyncio.run(process_mixed_text_with_edge(text, ja_voice, vi_voice))
    if not result:
        return "‚ùå L·ªói x·ª≠ l√Ω.", None

    audio_file = result.get("merged") or result.get("ja") or result.get("vi")
    return "‚úÖ Th√†nh c√¥ng!", audio_file


def launch_gui():
    with gr.Blocks() as demo:
        gr.Markdown("## üéôÔ∏è Text-to-Speech: Japanese & Vietnamese")

        with gr.Tabs():
            with gr.Tab("Edge TTS"):
                gr.Markdown("### Nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ t·∫°o audio")
                with gr.Row():
                    with gr.Column(scale=2):
                        input_text = gr.Textbox(label="Nh·∫≠p vƒÉn b·∫£n [JA. VI]", lines=4,
                                                placeholder="ÁßÅ„ÅØÁå´„ÅåÂ•Ω„Åç„Åß„Åô. T√¥i th√≠ch m√®o")
                        ja_voice_dropdown = gr.Dropdown(choices=VOICE_JA_TTS, label="Voice ti·∫øng Nh·∫≠t",
                                                        value=VOICE_JA_TTS[0])
                        vi_voice_dropdown = gr.Dropdown(choices=VOICE_VI_TTS, label="Voice ti·∫øng Vi·ªát",
                                                        value=VOICE_VI_TTS[0])
                        with gr.Row():
                            preview_btn = gr.Button("üîä Nghe th·ª≠ (Kh√¥ng l∆∞u)")
                            save_btn = gr.Button("üíæ T·∫°o & L∆∞u")
                        edge_status = gr.Textbox(label="Tr·∫°ng th√°i", interactive=False)

                    with gr.Column(scale=3):
                        edge_audio = gr.Audio(label="K·∫øt qu·∫£ Audio", type="filepath", interactive=False)
                        edge_preview_audio = gr.Audio(label="Preview", type="numpy", interactive=False)

                preview_btn.click(fn=preview_mixed_text_with_edge,
                                inputs=[input_text, ja_voice_dropdown, vi_voice_dropdown],
                                outputs=[edge_status, edge_preview_audio])

                save_btn.click(fn=run_async,
                            inputs=[input_text, ja_voice_dropdown, vi_voice_dropdown],
                            outputs=[edge_status, edge_audio])

            with gr.Tab("Google"):
                gr.Markdown("### TTS b·∫±ng Google gTTS (mi·ªÖn ph√≠)")
                with gr.Row():
                    with gr.Column(scale=2):
                        google_input = gr.Textbox(label="Nh·∫≠p vƒÉn b·∫£n", lines=4)
                        ja_voice = gr.Dropdown(GOOGLE_JA_VOICES, value="ja", label="Voice Japanese (Google)")
                        vi_voice = gr.Dropdown(GOOGLE_VI_VOICES, value="vi", label="Voice Vietnamese (Google)")

                        google_preview_btn = gr.Button("üîä Nghe th·ª≠ (Kh√¥ng l∆∞u)")
                        google_save_btn = gr.Button("üíæ T·∫°o & L∆∞u")
                        google_status = gr.Textbox(label="Tr·∫°ng th√°i", interactive=False)

                    with gr.Column(scale=3):
                        google_audio = gr.Audio(label="K·∫øt qu·∫£ Google Audio", type="filepath", interactive=False)
                        google_preview_audio = gr.Audio(label="Preview", type="numpy", interactive=False)

                    google_preview_btn.click(
                        fn=preview_mixed_text_with_google,
                        inputs=[google_input, ja_voice, vi_voice],
                        outputs=[google_status, google_preview_audio]
                    )

                    google_save_btn.click(
                        fn=process_mixed_text_with_google,
                        inputs=[google_input, ja_voice, vi_voice],
                        outputs=[google_status, google_audio]
                    )
    demo.launch()
